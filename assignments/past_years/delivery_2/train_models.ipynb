{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fcd644",
   "metadata": {},
   "source": [
    "## NLP Task 2: Artur Xarles & Enric Azuara - Train notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67d449",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec599b07",
   "metadata": {},
   "source": [
    "Import necessary packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94770c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skseq\n",
    "import skseq.readers.pos_corpus\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "from skseq.sequences.extended_feature import ExtendedFeatures\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbad365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfdd9f9",
   "metadata": {},
   "source": [
    "Read the train data to fit the different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6a2dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id          words tags\n",
       "0            0      Thousands    O\n",
       "1            0             of    O\n",
       "2            0  demonstrators    O\n",
       "3            0           have    O\n",
       "4            0        marched    O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train_data_ner.csv')\n",
    "test = pd.read_csv('./data/test_data_ner.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cfc95",
   "metadata": {},
   "source": [
    "### Build a corpus using train data that can construct sequences of words/taggs. Function Corpus declared in utils.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028c35dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 38366/38366 [02:17<00:00, 278.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#Define corpus that also returns sequence and use for train data\n",
    "corpus = Corpus()\n",
    "corpus.build_corpus(train)\n",
    "train_seq = corpus.read_sequence(train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69cdbdd",
   "metadata": {},
   "source": [
    "Check that the output of our function is correct in the first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773c4e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/0 1/0 2/0 3/0 4/0 5/0 6/1 7/0 8/0 9/0 10/0 11/0 12/1 13/0 14/0 9/0 15/0 1/0 16/2 17/0 18/0 19/0 20/0 21/0 \n",
      "['O' 'O' 'O' 'O' 'O' 'O' 'B-geo' 'O' 'O' 'O' 'O' 'O' 'B-geo' 'O' 'O' 'O'\n",
      " 'O' 'O' 'B-gpe' 'O' 'O' 'O' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "print(train_seq[0])\n",
    "print(train.tags[train.sentence_id == 0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101346e",
   "metadata": {},
   "source": [
    "We can see that it return the correct values for the tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4676cebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-tim': 3,\n",
       " 'B-org': 4,\n",
       " 'I-geo': 5,\n",
       " 'B-per': 6,\n",
       " 'I-per': 7,\n",
       " 'I-org': 8,\n",
       " 'B-art': 9,\n",
       " 'I-art': 10,\n",
       " 'I-tim': 11,\n",
       " 'I-gpe': 12,\n",
       " 'B-nat': 13,\n",
       " 'I-nat': 14,\n",
       " 'B-eve': 15,\n",
       " 'I-eve': 16}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a5306",
   "metadata": {},
   "source": [
    "We can also see the constructed dictionary for the tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbe44d",
   "metadata": {},
   "source": [
    "### Structured perceptron without added features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84216e51",
   "metadata": {},
   "source": [
    "We use the already given function IDFeatures to create a set of features for the train sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b11a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f1a5d",
   "metadata": {},
   "source": [
    "Once the features are constructed, we can initialize the structured perceptron class and train the model. We need to give as input the words dictionary, the tags dictionary and the feature mapper that determine the features for each feature. We train it for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7280cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b217cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.893815\n",
      "Epoch: 1 Accuracy: 0.931674\n",
      "Epoch: 2 Accuracy: 0.940913\n",
      "Epoch: 3 Accuracy: 0.946175\n",
      "Epoch: 4 Accuracy: 0.950018\n",
      "Epoch: 5 Accuracy: 0.952577\n",
      "Epoch: 6 Accuracy: 0.954425\n",
      "Epoch: 7 Accuracy: 0.956033\n",
      "Epoch: 8 Accuracy: 0.957185\n",
      "Epoch: 9 Accuracy: 0.958481\n",
      "Epoch: 10 Accuracy: 0.959217\n",
      "Epoch: 11 Accuracy: 0.960524\n",
      "Epoch: 12 Accuracy: 0.961121\n",
      "Epoch: 13 Accuracy: 0.961207\n",
      "Epoch: 14 Accuracy: 0.961983\n",
      "Wall time: 2h 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1cced",
   "metadata": {},
   "source": [
    "After that, we store the model in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f4a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_model(\"./fitted_models/model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7f3e0",
   "metadata": {},
   "source": [
    "### Structured perceptron adding features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad0f6b",
   "metadata": {},
   "source": [
    "In this case we add different features explained in the .pdf file that are related with the current and previous word, which can add valuable information to better classify the words to tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7f268",
   "metadata": {},
   "source": [
    "In this case we use the ExtendedFeatures class which is an extention of the IDFeatures one. It contains all the different features added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5893ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = ExtendedFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c320560d",
   "metadata": {},
   "source": [
    "Once we have constructed the feature mapper we initialize the structured perceptron and we train it for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc009453",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc703a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.934751\n",
      "Epoch: 1 Accuracy: 0.947807\n",
      "Epoch: 2 Accuracy: 0.951447\n",
      "Epoch: 3 Accuracy: 0.953468\n",
      "Epoch: 4 Accuracy: 0.955193\n",
      "Epoch: 5 Accuracy: 0.956500\n",
      "Epoch: 6 Accuracy: 0.957469\n",
      "Epoch: 7 Accuracy: 0.958749\n",
      "Epoch: 8 Accuracy: 0.959261\n",
      "Epoch: 9 Accuracy: 0.959952\n",
      "Epoch: 10 Accuracy: 0.960971\n",
      "Epoch: 11 Accuracy: 0.961128\n",
      "Epoch: 12 Accuracy: 0.961820\n",
      "Epoch: 13 Accuracy: 0.962563\n",
      "Epoch: 14 Accuracy: 0.962290\n",
      "Wall time: 2h 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376400ba",
   "metadata": {},
   "source": [
    "After that, we store the model in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e98b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_model(\"./fitted_models/model2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
